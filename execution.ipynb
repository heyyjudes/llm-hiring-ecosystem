{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from testing_scripts.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Creating a labeled dataframe\n",
    "This section involves reading in the resumes, filtering out entries whose CVs are too short, and creating positive and negative classes while filtering out all entries in neither class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From resumes parquet\n",
    "This subsection assumes the existence of the resumes parquet file, processes, and exports the Labeled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminepark/Documents/GitHub/llm-hiring-ecosystem/testing_scripts/label_resumes.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[TRUE_LABEL_COLUMN_NAME] = df.apply(label, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "# Read in the parquet\n",
    "RESUMES_PARQUET_INPUT_FILENAME = \"data/resumes.parquet\"\n",
    "raw_df = pd.read_parquet(RESUMES_PARQUET_INPUT_FILENAME, engine='pyarrow')  # raw dataframe\n",
    "\n",
    "# Filter the dataframe by minimum cv length\n",
    "MIN_CV_LENGTH = 500\n",
    "filtered_df = raw_df.loc[raw_df['CV'].dropna().apply(len) >= MIN_CV_LENGTH]\n",
    "\n",
    "# Add a true label column based on the specified keywords\n",
    "POSITIVE_POSITION = \"Project Manager\"\n",
    "POSITIVE_KEYWORD = \"Project Manager\"\n",
    "NEGATIVE_POSITION = \"QA Engineer\"   # \"Java Developer\"\n",
    "NEGATIVE_KEYWORD = \"QA\"             # \"Java\"\n",
    "\n",
    "import testing_scripts.label_resumes\n",
    "testing_scripts.label_resumes.add_true_label_column(filtered_df, POSITIVE_POSITION, POSITIVE_KEYWORD, NEGATIVE_POSITION, NEGATIVE_KEYWORD)\n",
    "labeled_df = filtered_df            # alias\n",
    "\n",
    "# Filter out entries whose true label is NA (i.e. belongs to neither class)\n",
    "labeled_df = labeled_df[labeled_df[\"True Label\"].notna()]\n",
    "\n",
    "# Export the labeled dataframe\n",
    "LABELED_DATAFRAME_OUTPUT_FILENAME = \"data/labeled_df.csv\"\n",
    "labeled_df.to_csv(LABELED_DATAFRAME_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From import\n",
    "If the labeled_df.csv file already exists, run this instead to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_DATAFRAME_INPUT_FILENAME = \"data/labeled_df.csv\"\n",
    "labeled_df = pd.read_csv(LABELED_DATAFRAME_INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True label playground\n",
    "This subsection contains some light code for examining the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label\n",
      "1    6753\n",
      "0    6379\n",
      "Name: count, dtype: int64\n",
      "proportion of positives = 0.5142400243679561\n"
     ]
    }
   ],
   "source": [
    "# The size of the positive and negative classes\n",
    "value_counts = labeled_df[\"True Label\"].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "positiveClassSize = value_counts.get(POSITIVE_LABEL, default=0)\n",
    "negativeClassSize = value_counts.get(NEGATIVE_LABEL, default=0)\n",
    "print(f\"Proportion of positives = {positiveClassSize / (positiveClassSize + negativeClassSize)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated positive CV:\n",
      "====================\n",
      " High levels of self-organization, structure, and attention to detail have helped build a successful career in advertising, as evidenced by hundreds of successfully completed projects, and train dozens of specialists. Previous experience is similar to project management methodologies used in the IT industry, including budgeting, planning, stakeholder management, risk mitigation, and effective communication. Creating new products inspires and motivates further development.\n",
      "Account director\n",
      "2018 - 2021\n",
      "Management and development of client portfolio. \n",
      "Control over project development and progress. \n",
      "Planning and budgeting based on client portfolio. \n",
      "Analysis of project effectiveness and profitability. \n",
      "Operational management: organizing, coordinating, and controlling the work of the account team (planning and task allocation). \n",
      "Ensuring effective interaction of the account managers team between agency departments.\n",
      "\n",
      "Senior account manager \n",
      "2017 - 2018\n",
      "Communication with clients. \n"
     ]
    }
   ],
   "source": [
    "# Example positive entry\n",
    "examplePositiveEntry = labeled_df.loc[labeled_df[\"True Label\"] == POSITIVE_LABEL].iloc[0]\n",
    "examplePositiveCV: str = examplePositiveEntry.to_dict()[\"CV\"]\n",
    "print(f\"Truncated positive CV:\\n====================\\n {examplePositiveCV[:1000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated negative CV:\n",
      "====================\n",
      " \n",
      "June/2022 - Present\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, documentation writing, writing/ updating test cases, testing with a database(postgresql), testing API requests, GitHub, TeamCity);\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke, Stress;\n",
      "- Experience with Automation tools (JS/ Playwright, test coverage (UI, API, Database));\n",
      "- Experience and understanding of Agile Development methodologies especially Scrum.\n",
      "\n",
      "December/2021 - June/2022\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, writing/updating test cases, testing API requests, GitHub);\n",
      "Î¼ Experience with Automation tools (JS/Cypress, test coverage (UI, API));\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke;\n",
      "- Experience and understanding of Agile Development methodologies especially Kanban.\n",
      "\n",
      "November/2021 - December/2021\n",
      "- Experience with QA/mobile tools(bug-reports, check-lists);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example negative entry \n",
    "exampleNegativeEntry = labeled_df.loc[labeled_df[\"True Label\"] == NEGATIVE_LABEL].iloc[10]\n",
    "exampleNegativeCV = exampleNegativeEntry.to_dict()[\"CV\"]\n",
    "print(f\"Truncated negative CV:\\n====================\\n {exampleNegativeCV[:1000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Marking samples for Experiments\n",
    "This section involves marking samples in the labeled dataframe for experiments. This allows us to experiment on a few samples at a time, rather than all entries at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From labeled_df\n",
    "This subsection assumes the existence of the labeled_df object within this notebook, processes, and exports the Marked dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples from each class we want to mark for experiments\n",
    "NUM_POSITIVE_SAMPLES = 100\n",
    "NUM_NEGATIVE_SAMPLES = 100\n",
    "\n",
    "# Create a new column \"Marked for Experiments\" and deterministically mark \n",
    "# the first NUM_POSITIVE_SAMPLES positive entries and the first NUM_NEGATIVE_SAMPLES negative entries True and all others false\n",
    "labeled_df[\"Marked for Experiments\"] = False\n",
    "positive_sample_indices = labeled_df[labeled_df[\"True Label\"] == POSITIVE_LABEL].index[:NUM_POSITIVE_SAMPLES]\n",
    "negative_sample_indices = labeled_df[labeled_df[\"True Label\"] == NEGATIVE_LABEL].index[:NUM_NEGATIVE_SAMPLES]\n",
    "labeled_df.loc[positive_sample_indices, \"Marked for Experiments\"] = True\n",
    "labeled_df.loc[negative_sample_indices, \"Marked for Experiments\"] = True\n",
    "marked_df = labeled_df          # alias\n",
    "\n",
    "# Export the marked dataframe\n",
    "MARKED_DATAFRAME_OUTPUT_FILENAME = \"data/marked_df.csv\"\n",
    "marked_df.to_csv(MARKED_DATAFRAME_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From import\n",
    "If the marked_df.csv file already exists, run this instead to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKED_DATAFRAME_INPUT_FILENAME = \"data/marked_df.csv\"\n",
    "marked_df = pd.read_csv(MARKED_DATAFRAME_INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark playground\n",
    "This subsection contains some light code for examining the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples = 200\n"
     ]
    }
   ],
   "source": [
    "# The total number of marked entries (should match NUM_POSITIVE_SAMPLES + NUM_NEGATIVE_SAMPLES)\n",
    "value_counts = marked_df[\"Marked for Experiments\"].value_counts()\n",
    "print(f\"Number of samples = {value_counts.get(True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('hiring-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ef90e252922ec218579f878e8875693d0f6f915d658626d8644d9a71eb203b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
