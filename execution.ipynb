{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import testing_scripts.constants as constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Creating a labeled dataframe\n",
    "This section involves reading in the resumes, filtering out entries whose CVs are too short, and creating positive and negative classes while filtering out all entries in neither class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From resumes parquet\n",
    "This subsection assumes the existence of the resumes parquet file, processes, and exports the Labeled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminepark/Documents/GitHub/llm-hiring-ecosystem/testing_scripts/label_resumes.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[TRUE_LABEL_COLUMN_NAME] = df.apply(label, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "# Read in the parquet\n",
    "RESUMES_PARQUET_INPUT_FILENAME = \"data/resumes.parquet\"\n",
    "raw_df = pd.read_parquet(RESUMES_PARQUET_INPUT_FILENAME, engine='pyarrow')  # raw dataframe\n",
    "\n",
    "# Filter the dataframe by minimum cv length\n",
    "MIN_CV_LENGTH = 500\n",
    "filtered_df = raw_df.loc[raw_df['CV'].dropna().apply(len) >= MIN_CV_LENGTH]\n",
    "\n",
    "# Add a true label column based on the specified keywords\n",
    "import testing_scripts.label_resumes\n",
    "testing_scripts.label_resumes.add_true_label_column(filtered_df, constants.POSITIVE_POSITION, constants.POSITIVE_KEYWORD, constants.NEGATIVE_POSITION, constants.NEGATIVE_KEYWORD)\n",
    "labeled_df = filtered_df            # alias\n",
    "\n",
    "# Filter out entries whose true label is NA (i.e. belongs to neither class)\n",
    "labeled_df = labeled_df[labeled_df[\"True Label\"].notna()]\n",
    "\n",
    "# Export the labeled dataframe\n",
    "LABELED_DATAFRAME_OUTPUT_FILENAME = \"data/labeled_df.csv\"\n",
    "labeled_df.to_csv(LABELED_DATAFRAME_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From import\n",
    "If the labeled_df.csv file already exists, run this instead to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_DATAFRAME_INPUT_FILENAME = \"data/labeled_df.csv\"\n",
    "labeled_df = pd.read_csv(LABELED_DATAFRAME_INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True label playground\n",
    "This subsection contains some light code for examining the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the positive and negative classes\n",
    "value_counts = labeled_df[\"True Label\"].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "positiveClassSize = value_counts.get(constants.POSITIVE_LABEL, default=0)\n",
    "negativeClassSize = value_counts.get(constants.NEGATIVE_LABEL, default=0)\n",
    "print(f\"Proportion of positives = {positiveClassSize / (positiveClassSize + negativeClassSize)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated positive CV:\n",
      "====================\n",
      " High levels of self-organization, structure, and attention to detail have helped build a successful career in advertising, as evidenced by hundreds of successfully completed projects, and train dozens of specialists. Previous experience is similar to project management methodologies used in the IT industry, including budgeting, planning, stakeholder management, risk mitigation, and effective communication. Creating new products inspires and motivates further development.\n",
      "Account director\n",
      "2018 - 2021\n",
      "Management and development of client portfolio. \n",
      "Control over project development and progress. \n",
      "Planning and budgeting based on client portfolio. \n",
      "Analysis of project effectiveness and profitability. \n",
      "Operational management: organizing, coordinating, and controlling the work of the account team (planning and task allocation). \n",
      "Ensuring effective interaction of the account managers team between agency departments.\n",
      "\n",
      "Senior account manager \n",
      "2017 - 2018\n",
      "Communication with clients. \n"
     ]
    }
   ],
   "source": [
    "# Example positive entry\n",
    "example_positive_entry = labeled_df.loc[labeled_df[\"True Label\"] == constants.POSITIVE_LABEL].iloc[0]\n",
    "example_positive_cv: str = example_positive_entry.to_dict()[\"CV\"]\n",
    "print(f\"Truncated positive CV:\\n====================\\n {example_positive_cv[:1000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example negative entry \n",
    "example_negative_entry = labeled_df.loc[labeled_df[\"True Label\"] == constants.NEGATIVE_LABEL].iloc[10]\n",
    "exampleNegativeCV = example_negative_entry.to_dict()[\"CV\"]\n",
    "print(f\"Truncated negative CV:\\n====================\\n {exampleNegativeCV[:1000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Marking samples for Experiments\n",
    "This section involves marking samples in the labeled dataframe for experiments. This allows us to experiment on a few samples at a time, rather than all entries at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From labeled_df\n",
    "This subsection assumes the existence of the labeled_df object within this notebook, processes, and exports the Marked dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples from each class we want to mark for experiments\n",
    "NUM_POSITIVE_SAMPLES = 100\n",
    "NUM_NEGATIVE_SAMPLES = 100\n",
    "\n",
    "# Create a new column \"Marked for Experiments\" and deterministically mark \n",
    "# the first NUM_POSITIVE_SAMPLES positive entries and the first NUM_NEGATIVE_SAMPLES negative entries True and all others false\n",
    "labeled_df[\"Marked for Experiments\"] = False\n",
    "positive_sample_indices = labeled_df[labeled_df[\"True Label\"] == constants.POSITIVE_LABEL].index[:NUM_POSITIVE_SAMPLES]\n",
    "negative_sample_indices = labeled_df[labeled_df[\"True Label\"] == constants.NEGATIVE_LABEL].index[:NUM_NEGATIVE_SAMPLES]\n",
    "labeled_df.loc[positive_sample_indices, \"Marked for Experiments\"] = True\n",
    "labeled_df.loc[negative_sample_indices, \"Marked for Experiments\"] = True\n",
    "marked_df = labeled_df          # alias\n",
    "\n",
    "# Export the marked dataframe\n",
    "MARKED_DATAFRAME_OUTPUT_FILENAME = \"data/marked_df.csv\"\n",
    "marked_df.to_csv(MARKED_DATAFRAME_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From import\n",
    "If the marked_df.csv file already exists, run this instead to import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKED_DATAFRAME_INPUT_FILENAME = \"data/marked_df.csv\"\n",
    "marked_df = pd.read_csv(MARKED_DATAFRAME_INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark playground\n",
    "This subsection contains some light code for examining the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of marked entries (should match NUM_POSITIVE_SAMPLES + NUM_NEGATIVE_SAMPLES)\n",
    "value_counts = marked_df[\"Marked for Experiments\"].value_counts()\n",
    "print(f\"Number of samples = {value_counts.get(True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Generating resumes for Experiments\n",
    "This section involves generating resumes tailored toward a specific job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From marked_df\n",
    "This subsection assumes the existence of the marked_df object within this notebook and generates modified resumes tailored toward the job specified in constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Marked for Experiments\" and deterministically mark \n",
    "# the first NUM_POSITIVE_SAMPLES positive entries and the first NUM_NEGATIVE_SAMPLES negative entries True and all others false\n",
    "# labeled_df[\"Marked for Experiments\"] = False\n",
    "# positive_sample_indices = labeled_df[labeled_df[\"True Label\"] == constants.POSITIVE_LABEL].index[:NUM_POSITIVE_SAMPLES]\n",
    "# negative_sample_indices = labeled_df[labeled_df[\"True Label\"] == constants.NEGATIVE_LABEL].index[:NUM_NEGATIVE_SAMPLES]\n",
    "# labeled_df.loc[positive_sample_indices, \"Marked for Experiments\"] = True\n",
    "# labeled_df.loc[negative_sample_indices, \"Marked for Experiments\"] = True\n",
    "# marked_df = labeled_df          # alias\n",
    "\n",
    "# # Export the marked dataframe\n",
    "# MARKED_DATAFRAME_OUTPUT_FILENAME = \"data/marked_df.csv\"\n",
    "# marked_df.to_csv(MARKED_DATAFRAME_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import testing_scripts.generate_resumes as generate_resumes\n",
    "\n",
    "print(f\"Example positive CV = {example_positive_cv}\\n\\n\")\n",
    "\n",
    "example_tailored_positive_cv = generate_resumes.tailor_resume(example_positive_cv, job_description = constants.JOB_DESCRIPTION, model_name = constants.MODEL_NAME)\n",
    "\n",
    "print(f\"Example positive tailored CV = {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('hiring-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ef90e252922ec218579f878e8875693d0f6f915d658626d8644d9a71eb203b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
