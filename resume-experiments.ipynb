{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01ae009",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ch/miniforge3/envs/finaljobsllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import Counter\n",
    "import operator as op\n",
    "\n",
    "import os\n",
    "from together import Together\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from testing_scripts.cleandataframe import trueLabelFunction\n",
    "from testing_scripts.generate_resumes import create_modified_resumes\n",
    "from testing_scripts.score_resumes import get_score\n",
    "from testing_scripts.score_resumes import append_scores\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do:  conda install conda-forge::qdrant-client\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9326e",
   "metadata": {},
   "source": [
    "## Section 1: Existing CVs data analysis\n",
    "\n",
    "Here is a recent collection of CVs from https://github.com/Stereotypes-in-LLMs/recruitment-dataset \n",
    "We will use these CVs as the basis for generating cover letters for our hiring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a279dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/resumes.parquet', engine='pyarrow')  # raw dataframe\n",
    "\n",
    "# Filter the dataframe minimum cv length\n",
    "MIN_CV_LENGTH = 500\n",
    "filtered_df = df.loc[df['CV'].dropna().apply(len) >= MIN_CV_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d904c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Moreinfo  Looking For  Highlights  \\\n",
      "Position                                                        \n",
      "Project Manager                 5299         2582        3298   \n",
      "QA Engineer                     4886         2392        2577   \n",
      "Junior QA Engineer              3333         1847        2206   \n",
      "Front-end developer             3045         1602        1475   \n",
      "Manual QA Engineer              2683         1243        1349   \n",
      "UI/UX Designer                  2521         1303        1364   \n",
      "Java Developer                  2246         1257        1167   \n",
      "IT Recruiter                    1947          852         844   \n",
      "Junior Front-end Developer      1861         1116        1270   \n",
      "UX/UI Designer                  1771          967        1002   \n",
      "Front-End Developer             1744          914         891   \n",
      "Business Analyst                1710          794         947   \n",
      "Python Developer                1509          835         821   \n",
      "Product manager                 1309          678         867   \n",
      "Frontend Developer              1296          725         665   \n",
      "Senior Software Engineer        1260          719         720   \n",
      "Junior Project Manager          1203          575         746   \n",
      "Full Stack Web Developer        1177          531         528   \n",
      "Senior QA Engineer              1139          651         642   \n",
      "Software Engineer               1119          591         597   \n",
      "\n",
      "                            Primary Keyword  English Level  Experience Years  \\\n",
      "Position                                                                       \n",
      "Project Manager                        5299           5293              5299   \n",
      "QA Engineer                            4886           4878              4886   \n",
      "Junior QA Engineer                     3333           3329              3333   \n",
      "Front-end developer                    3045           3044              3045   \n",
      "Manual QA Engineer                     2683           2683              2683   \n",
      "UI/UX Designer                         2521           2521              2521   \n",
      "Java Developer                         2245           2244              2246   \n",
      "IT Recruiter                           1947           1947              1947   \n",
      "Junior Front-end Developer             1861           1861              1861   \n",
      "UX/UI Designer                         1771           1771              1771   \n",
      "Front-End Developer                    1744           1744              1744   \n",
      "Business Analyst                       1710           1707              1710   \n",
      "Python Developer                       1509           1508              1509   \n",
      "Product manager                        1309           1309              1309   \n",
      "Frontend Developer                     1296           1296              1296   \n",
      "Senior Software Engineer               1260           1260              1260   \n",
      "Junior Project Manager                 1203           1203              1203   \n",
      "Full Stack Web Developer               1177           1177              1177   \n",
      "Senior QA Engineer                     1139           1139              1139   \n",
      "Software Engineer                      1119           1118              1119   \n",
      "\n",
      "                              CV  CV_lang    id  __index_level_0__  \n",
      "Position                                                            \n",
      "Project Manager             5299     5299  5299               5299  \n",
      "QA Engineer                 4886     4886  4886               4886  \n",
      "Junior QA Engineer          3333     3333  3333               3333  \n",
      "Front-end developer         3045     3045  3045               3045  \n",
      "Manual QA Engineer          2683     2683  2683               2683  \n",
      "UI/UX Designer              2521     2521  2521               2521  \n",
      "Java Developer              2246     2246  2246               2246  \n",
      "IT Recruiter                1947     1947  1947               1947  \n",
      "Junior Front-end Developer  1861     1861  1861               1861  \n",
      "UX/UI Designer              1771     1771  1771               1771  \n",
      "Front-End Developer         1744     1744  1744               1744  \n",
      "Business Analyst            1710     1710  1710               1710  \n",
      "Python Developer            1509     1509  1509               1509  \n",
      "Product manager             1309     1309  1309               1309  \n",
      "Frontend Developer          1296     1296  1296               1296  \n",
      "Senior Software Engineer    1260     1260  1260               1260  \n",
      "Junior Project Manager      1203     1203  1203               1203  \n",
      "Full Stack Web Developer    1177     1177  1177               1177  \n",
      "Senior QA Engineer          1139     1139  1139               1139  \n",
      "Software Engineer           1119     1119  1119               1119  \n"
     ]
    }
   ],
   "source": [
    "# See the top 20 most frequent positions\n",
    "top20df = filtered_df.groupby(\"Position\").count().sort_values(\"Moreinfo\", ascending=False).head(20)\n",
    "print(top20df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc22a6f",
   "metadata": {},
   "source": [
    "### True Labels (Positive and Negative Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e851727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a true label column\n",
    "labeled_df = filtered_df.copy()\n",
    "labeled_df[\"True Label\"] = labeled_df.apply(trueLabelFunction, axis=1)\n",
    "labeled_df = labeled_df[labeled_df[\"True Label\"].notna()]       # Filter out rows whose label value is NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548b81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label\n",
      "1    6753\n",
      "0    6379\n",
      "Name: count, dtype: int64\n",
      "proportion of positives = 0.5142400243679561\n"
     ]
    }
   ],
   "source": [
    "# Prints the sizes of the positive and negative class\n",
    "value_counts = labeled_df[\"True Label\"].value_counts()\n",
    "print(value_counts)\n",
    "POSITIVE_LABEL, NEGATIVE_LABEL = 1,0\n",
    "positiveClassSize = value_counts.get(POSITIVE_LABEL, default=0)\n",
    "negativeClassSize = value_counts.get(NEGATIVE_LABEL, default=0)\n",
    "# print(f\"positiveClassSize = {positiveClassSize}\")\n",
    "# print(f\"negativeClassSize = {negativeClassSize}\")\n",
    "print(f\"proportion of positives = {positiveClassSize / (positiveClassSize + negativeClassSize)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa9edf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High levels of self-organization, structure, and attention to detail have helped build a successful career in advertising, as evidenced by hundreds of successfully completed projects, and train dozens of specialists. Previous experience is similar to project management methodologies used in the IT industry, including budgeting, planning, stakeholder management, risk mitigation, and effective communication. Creating new products inspires and motivates further development.\n",
      "Account director\n",
      "2018 - 2021\n",
      "Management and development of client portfolio. \n",
      "Control over project development and progress. \n",
      "Planning and budgeting based on client portfolio. \n",
      "Analysis of project effectiveness and profitability. \n",
      "Operational management: organizing, coordinating, and controlling the work of the account team (planning and task allocation). \n",
      "Ensuring effective interaction of the account managers team between agency departments.\n",
      "\n",
      "Senior account manager \n",
      "2017 - 2018\n",
      "Communication with clients. \n",
      "Budgeting. \n",
      "Task allocation, organizing, and managing team work. \n",
      "Planning. \n",
      "Interaction and control over subcontractors' work. \n",
      "Contract management, reporting preparation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example positive entry \n",
    "examplePositiveEntry = labeled_df.loc[labeled_df[\"True Label\"] == POSITIVE_LABEL].iloc[0]\n",
    "print(examplePositiveEntry.to_dict()[\"CV\"])\n",
    "# print(\"\".join(examplePositiveEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4de7270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "June/2022 - Present\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, documentation writing, writing/ updating test cases, testing with a database(postgresql), testing API requests, GitHub, TeamCity);\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke, Stress;\n",
      "- Experience with Automation tools (JS/ Playwright, test coverage (UI, API, Database));\n",
      "- Experience and understanding of Agile Development methodologies especially Scrum.\n",
      "\n",
      "December/2021 - June/2022\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, writing/updating test cases, testing API requests, GitHub);\n",
      "μ Experience with Automation tools (JS/Cypress, test coverage (UI, API));\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke;\n",
      "- Experience and understanding of Agile Development methodologies especially Kanban.\n",
      "\n",
      "November/2021 - December/2021\n",
      "- Experience with QA/mobile tools(bug-reports, check-lists);\n",
      "- Experience with a Regression tests, Integration, Functional tests, Smoke.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example negative entry \n",
    "exampleNegativeEntry = labeled_df.loc[labeled_df[\"True Label\"] == NEGATIVE_LABEL].iloc[10]\n",
    "print(exampleNegativeEntry.to_dict()[\"CV\"])\n",
    "# print(\"\".join(exampleNegativeEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08830b8e",
   "metadata": {},
   "source": [
    "## Section 2: Prompting LLMs for generating cover letters \n",
    "\n",
    "Now we will use a generic prompt to generate a cover letters for each resume using API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9968e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "with open('llm_api_keys.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "together_api_key = config['services']['together']['api_key'] # replace with openai or anthropic also in yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f48e3c4-fb69-4314-9ab4-d3e0b68a4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example usage of Together AI \n",
    "client = Together(api_key=together_api_key) \n",
    "position = \"Project Manager\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "     model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "     messages=[{\"role\": \"user\", \"content\": \"Modify this resume to help me get a \"+ position+\" Job:\" + \"\".join(\"\".join(exampleNegativeEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))}],\n",
    " )\n",
    "coverletter = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e40e28-5177-4645-9ccc-a0bab721bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **PROFESSIONAL EXPERIENCE**\n",
      "\n",
      "**Project Manager (Present)**\n",
      "\n",
      "*Currently managing and overseeing projects, ensuring successful planning, execution, and delivery within budget and timeline.*\n",
      "\n",
      "* Experience with QA/Web tools including bug-reports, check-lists, documentation writing, test case development and maintenance, PostgreSQL, API testing, GitHub, and TeamCity.\n",
      "* Proficient in automation tools such as JS/Playwright and Cypress, with a strong understanding of test coverage for UI, API, and database.\n",
      "* Extensive experience in various types of testing including regression, integration, functional, end-to-end, acceptance, smoke, and stress testing.\n",
      "* Strong understanding of Agile Development methodologies, particularly Scrum and Kanban.\n",
      "\n",
      "**QA Automation Engineer (June/2022 - December/2021)**\n",
      "\n",
      "*Led QA automation efforts for various projects, implementing best practices and improving testing processes.*\n",
      "\n",
      "* Experience with QA/Web tools including bug-reports, check-lists, writing/updating test cases, testing API requests, and GitHub.\n",
      "* Proficient in automation tools such as JS/Cypress and Playwright, with a strong understanding of test coverage for UI and API.\n",
      "* Conducted various types of testing including regression, integration, functional, end-to-end, acceptance, smoke testing.\n",
      "* Implemented Agile Development methodologies, particularly Scrum and Kanban.\n",
      "\n",
      "**QA Engineer (November/2021 - June/2022)**\n",
      "\n",
      "*Managed QA efforts for mobile projects, ensuring high-quality deliverables and efficient testing processes.*\n",
      "\n",
      "* Experience with QA/mobile tools including bug-reports, check-lists.\n",
      "* Conducted various types of testing including regression, integration, functional, and smoke testing.\n",
      "* Implemented Agile Development methodologies, particularly Kanban.\n",
      "\n",
      "**SKILLS**\n",
      "\n",
      "* Project Management\n",
      "* QA/Web Tools (bug-reports, check-lists, documentation writing, test case development and maintenance, PostgreSQL, API testing, GitHub, TeamCity)\n",
      "* Automation Tools (JS/Playwright, Cypress, test coverage)\n",
      "* Agile Development Methodologies (Scrum, Kanban)\n",
      "* Regression, Integration, Functional, End-to-end, Acceptance, Smoke, Stress Testing\n",
      "\n",
      "**EDUCATION**\n",
      "\n",
      "*Bachelor's Degree in Computer Science*\n",
      "\n",
      "*Certified Scrum Master (CSM)*\n",
      "\n",
      "*Certified Software Development Professional (CSDP)*\n"
     ]
    }
   ],
   "source": [
    "print(coverletter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8aa7011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69644\n",
      "69645\n",
      "69646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ch/Desktop/AI-Research/llm-hiring-ecosystem/testing_scripts/generate_resumes.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[newposition+\" Modified CV\"] = all_modified_resumes\n"
     ]
    }
   ],
   "source": [
    "# Generate resumes\n",
    "\n",
    "df = pd.read_parquet('data/resumes.parquet', engine='pyarrow')\n",
    "\n",
    "java_dev_occupation_df = df[df[\"Position\"]==\"Java Developer\"]\n",
    "\n",
    "java_to_pm_mod_resume = create_modified_resumes(java_dev_occupation_df, 2, \"java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb97ee",
   "metadata": {},
   "source": [
    "## Section 3: Training a simple hiring model \n",
    "\n",
    "We will now use fast text to create a hiring model which will make a binary decision of whether we should hire a candidate or not based on years of experience as the ground truth. Fasttext (https://fasttext.cc/) is an easy to use library you can run on your local computer to build text classification models or get embedding representations for different inputs. Here we will use Fast text to generate embeddings and then use a logistic classifier on top of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b060e-4529-498f-97ee-b4a3016d65e0",
   "metadata": {},
   "source": [
    "### Step 1: Generate embeddings from cover letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b689cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fast text vectors\n",
    "import fasttext\n",
    "#FASTTEXT_MODEL_FILEPATH = \"./cc.en.300.bin\"      \n",
    "FASTTEXT_MODEL_FILEPATH = '../../../Downloads/cc.en.300.bin'\n",
    "ft = fasttext.load_model(FASTTEXT_MODEL_FILEPATH) # replace with your own path to the vector binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b345dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have certificates of successful completion of QATestLab and DataArt testing courses. I was the best support engineer for a few months in my company. Apart from that I also took part in managing support team.',\n",
       " \"Testing new features and new platforms(for online chat), testing company’s website, finding errors in the system and sending them to system administrators for correction. All my experience before that I got at the courses of testing during my homeworks. In my homeworks I was doing Test Plan, Test Cases, Check Lists, Bug Reports, User stories and wrote metricks about completed work. My homeworks was checked and appreciated. I'm going to start my career in IT with manual testing and in the future, become to automation.\",\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\".join(labeled_df.iloc[12229].to_dict()['CV']).split('\\r\\n').split('\\n')\n",
    "\"\".join(labeled_df.iloc[12229].to_dict()['CV'].split('\\r\\n')).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eb52179",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_doordash_pm = \"Tailor my resume to this job description and not make anything up: Product Manager (Multiple Levels) - Doordash: About the Team At DoorDash, we're redefining the future of on-demand delivery. To do this, we're building a world-class product organization, in which each of our product managers play a critical role in helping to define and execute our vision to connect local delivery networks in cities all across the world! About The Role Product Managers at DoorDash require a sharp consumer-first eye, platform thinking and strong cross-functional collaboration. As a Product Manager at DoorDash, you will own the product strategy and vision, define the product roadmap and alignment, and help drive the execution. You will be working on mission-critical products that shape the direction of the company. You will report into one of the following pillars: Merchant, Consumer, Operational Excellence, Ads, Logistics, or New Verticals. This role is a hybrid of remote work and in-person collaboration. You’re Excited About This Opportunity Because You Will… Drive the product definition, strategy, and long term vision. You own the roadmap Work closely with cross-functional teams of designers, operators, data scientists and engineers Communicate product plans, benefits and results to key stakeholders including leadership team We’re Excited About You Because… You have 5+ years of Product Management Industry Experience You have 4+ years of user-facing experience in industries such as eCommerce, technology or multi-sided marketplaces You have proven abilities in driving product strategy, vision, and roadmap alignment You’re an execution power-house You have experience presenting business reviews to senior executives You have empathy for the users you build for You are passionate about DoorDash and the problems we are solving for About DoorDash At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more. Our Commitment to Diversity and Inclusion We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel. Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on 'protected categories,' we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination. Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation. If you need any accommodations, please inform your recruiting contact upon initial connection.\"\n",
    "resumm = \"\".join(labeled_df.loc[129969].to_dict()['CV'].split('\\r\\n')).split('\\n')\n",
    "resume_qa = \"01.07.2019 - current, QA engineer, Zoolatech On the daily basis, I'm working on implementation, refactoring and improvements of automation test scenarios using Selenium with Java. Purpose improvements into automation test framework. Work with cross-functional teams to identify and develop test cases for functional testing. Provide reports to management on the automation sprint backlog, timing, schedule and results. During my time at Zoolatech got acquainted with such tools as 'Selenium', 'Gitlab', 'Maven', 'TestNG', 'REST Assured', 'JSON.Simple', 'BrowserStack'. Got experience with Page Object Model approach, used Dev Tool to identify Web Elements XPath 01.06.2018 - 01.07.2019, QA engineer, Global Logic On the daily basis, I have been working on creating test cases for new features, updating existing test cases accordingly to the new features, running execution records, open and verifying defects. Gained experience working in an international Scrum team with all appropriate activities. During my time at GlobalLogic got acquainted with such tools as 'Putty', 'WinSCP', 'Cygwin', 'Postman', 'pgAdmin'. Improved business communication skills inside the team (participation in meetings and emailing with Toronto based teammates). Got experience in mentoring and knowledge sharing of product functionality with our new team members. 01.07.2017 - 01.06.2018, QA engineer, Lemonade Agency While working at the Lemonade Agency I gained experience in testing desktop games and mobile applications for IOS and Android, creating bug reports, test cases, and checklists. Got experience working with technical documentation on commercial projects. On the daily basis, I have been working with such programs as Fiddler, Reflector, Adobe Scout, etc.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89517210-8189-4e61-9af8-643ac321be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vector representation of a multiword string using fasttex embeddings\n",
    "def get_vector_rep(text: str): \n",
    "    tokens = text.lower().split() # feel free to use other tokenizations if you want\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        print(tokens)\n",
    "        print(text)\n",
    "        print(len(text))\n",
    "    \n",
    "    for (i, t) in enumerate(tokens):\n",
    "        if i == 0:\n",
    "            vec = ft.get_word_vector(t)\n",
    "        else:\n",
    "            vec += ft.get_word_vector(t)\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.pairwise.cosine_similarity(get_vector_rep(\"in the mood to\").reshape(-1, 1), get_vector_rep(\"hi there\").reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def8b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.59\n"
     ]
    }
   ],
   "source": [
    "#Get_score \n",
    "result = get_score(job_doordash_pm, resumm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3b1af-bf5c-470e-8f64-c00d131b44b4",
   "metadata": {},
   "source": [
    "### Step 2: Build classifier for resume classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab74eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_train_dataset(true_dataset, false_dataset):\n",
    "    x_s = []\n",
    "    y_s = []\n",
    "    for cv_s in true_dataset:\n",
    "        x_s.append(get_vector_rep(\"\".join(\"\".join(cv_s.split('\\r\\n')).split('\\n'))))\n",
    "        y_s.append(1)\n",
    "    for cv_s in false_dataset:\n",
    "        x_s.append(get_vector_rep(\"\".join(\"\".join(cv_s.split('\\r\\n')).split('\\n'))))\n",
    "        y_s.append(0)\n",
    "    return [x_s, y_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3e37d-fa1f-4304-9f5f-54867b970a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build vector embeddings and lables for positive label examples experience more than 5 years, negative examples less than 5\n",
    "training_data = create_test_train_dataset(datasets[1], datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061ee07-d3b3-4d0a-b050-f91a6a1ad859",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_applicant_modification_data = [training_data[0], training_data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates (model, x_test, y_test) based on input (x, y) data\n",
    "def train_model(data):\n",
    "    x = data[0]\n",
    "    y=data[1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "    clf = LogisticRegression(random_state=16)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    p = clf.predict_proba(x_test)[:, 1]\n",
    "    p_acc = accuracy_score(y_test, p > 0.5)\n",
    "    print(\"clf_acc\", p_acc)\n",
    "    return [clf, x_test, y_test]\n",
    "\n",
    "#Plots confusion matrix\n",
    "def plot_conf_matrix(xtest, ytest, output_model):\n",
    "    cnf_matrix = metrics.confusion_matrix(ytest, output_model.predict(xtest))\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix', y=1.1)\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89453ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resumes = []\n",
    "\n",
    "with open(\"javadeveloper_to_pm.text\", 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line) >1:\n",
    "            test_resumes.append(get_vector_rep(line))\n",
    "        #print(\"new\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebba9c-71f0-494d-9801-a60086502244",
   "metadata": {},
   "source": [
    "### Section 4: Simulate Evaluations on Score & Evaluate Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d317adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find a separating hyperplane?\n",
    " https://stackoverflow.com/questions/38657138/scikits-learn-svm-1-dimensional-separating-hyperplane\n",
    " '''\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe17fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_resumes=pd.read_csv(\"data/Scored_Resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "pos = np.hstack((np.random.randn(20, 1) + 1, np.zeros((20, 1))))\n",
    "neg = np.hstack((np.random.randn(20, 1) - 1, np.zeros((20, 1))))\n",
    "X = np.r_[pos, neg]\n",
    "Y = [0] * 20 + [1] * 20\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, Y)\n",
    "w = clf.coef_[0]\n",
    "x_0 = -clf.intercept_[0]/w[0]\n",
    "margin = w[0]\n",
    "\n",
    "plt.figure()\n",
    "x_min, x_max = np.floor(X.min()), np.ceil(X.max())\n",
    "y_min, y_max = -3, 3\n",
    "yy = np.linspace(y_min, y_max)\n",
    "XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "Z = clf.predict(np.c_[XX.ravel(), np.zeros(XX.size)]).reshape(XX.shape)\n",
    "plt.pcolormesh(XX, YY, Z, cmap=plt.cm.Paired)\n",
    "plt.plot(x_0*np.ones(shape=yy.shape), yy, 'k-')\n",
    "plt.plot(x_0*np.ones(shape=yy.shape) - margin, yy, 'k--')\n",
    "plt.plot(x_0*np.ones(shape=yy.shape) + margin, yy, 'k--')\n",
    "plt.scatter(pos, np.zeros(shape=pos.shape), s=80, marker='o', facecolors='none')\n",
    "plt.scatter(neg, np.zeros(shape=neg.shape), s=80, marker='^', facecolors='none')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ef90e252922ec218579f878e8875693d0f6f915d658626d8644d9a71eb203b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
