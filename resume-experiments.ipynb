{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b01ae009",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import Counter\n",
    "import operator as op\n",
    "\n",
    "import os\n",
    "from together import Together\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from testing_scripts.cleandataframe import trueLabelFunction\n",
    "from testing_scripts.generate_resumes import create_modified_resumes\n",
    "from testing_scripts.score_resumes import get_score\n",
    "from testing_scripts.score_resumes import append_scores\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do:  conda install conda-forge::qdrant-client\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9326e",
   "metadata": {},
   "source": [
    "## Section 1: Existing CVs data analysis\n",
    "\n",
    "Here is a recent collection of CVs from https://github.com/Stereotypes-in-LLMs/recruitment-dataset \n",
    "We will use these CVs as the basis for generating cover letters for our hiring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a279dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/resumes.parquet', engine='pyarrow')  # raw dataframe\n",
    "\n",
    "# Filter the dataframe minimum cv length\n",
    "MIN_CV_LENGTH = 500\n",
    "filtered_df = df.loc[df['CV'].dropna().apply(len) >= MIN_CV_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the top 20 most frequent positions\n",
    "top20df = filtered_df.groupby(\"Position\").count().sort_values(\"Moreinfo\", ascending=False).head(20)\n",
    "print(top20df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc22a6f",
   "metadata": {},
   "source": [
    "### True Labels (Positive and Negative Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e851727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a true label column\n",
    "labeled_df = filtered_df.copy()\n",
    "labeled_df[\"True Label\"] = labeled_df.apply(trueLabelFunction, axis=1)\n",
    "labeled_df = labeled_df[labeled_df[\"True Label\"].notna()]       # Filter out rows whose label value is NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "548b81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label\n",
      "1    6753\n",
      "0    6379\n",
      "Name: count, dtype: int64\n",
      "proportion of positives = 0.5142400243679561\n"
     ]
    }
   ],
   "source": [
    "# Prints the sizes of the positive and negative class\n",
    "value_counts = labeled_df[\"True Label\"].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "positiveClassSize = value_counts.get(POSITIVE_LABEL, default=0)\n",
    "negativeClassSize = value_counts.get(NEGATIVE_LABEL, default=0)\n",
    "# print(f\"positiveClassSize = {positiveClassSize}\")\n",
    "# print(f\"negativeClassSize = {negativeClassSize}\")\n",
    "print(f\"proportion of positives = {positiveClassSize / (positiveClassSize + negativeClassSize)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa9edf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High levels of self-organization, structure, and attention to detail have helped build a successful career in advertising, as evidenced by hundreds of successfully completed projects, and train dozens of specialists. Previous experience is similar to project management methodologies used in the IT industry, including budgeting, planning, stakeholder management, risk mitigation, and effective communication. Creating new products inspires and motivates further development.\n",
      "Account director\n",
      "2018 - 2021\n",
      "Management and development of client portfolio. \n",
      "Control over project development and progress. \n",
      "Planning and budgeting based on client portfolio. \n",
      "Analysis of project effectiveness and profitability. \n",
      "Operational management: organizing, coordinating, and controlling the work of the account team (planning and task allocation). \n",
      "Ensuring effective interaction of the account managers team between agency departments.\n",
      "\n",
      "Senior account manager \n",
      "2017 - 2018\n",
      "Communication with clients. \n",
      "Budgeting. \n",
      "Task allocation, organizing, and managing team work. \n",
      "Planning. \n",
      "Interaction and control over subcontractors' work. \n",
      "Contract management, reporting preparation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example positive entry \n",
    "examplePositiveEntry = labeled_df.loc[labeled_df[\"True Label\"] == POSITIVE_LABEL].iloc[0]\n",
    "print(examplePositiveEntry.to_dict()[\"CV\"])\n",
    "# print(\"\".join(examplePositiveEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4de7270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "June/2022 - Present\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, documentation writing, writing/ updating test cases, testing with a database(postgresql), testing API requests, GitHub, TeamCity);\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke, Stress;\n",
      "- Experience with Automation tools (JS/ Playwright, test coverage (UI, API, Database));\n",
      "- Experience and understanding of Agile Development methodologies especially Scrum.\n",
      "\n",
      "December/2021 - June/2022\n",
      "- Experience with QA/Web tools (bug-reports, check-lists, writing/updating test cases, testing API requests, GitHub);\n",
      "Î¼ Experience with Automation tools (JS/Cypress, test coverage (UI, API));\n",
      "- Experience with a Regression tests, Integration, Functional tests, End-to-end, Acceptance, Smoke;\n",
      "- Experience and understanding of Agile Development methodologies especially Kanban.\n",
      "\n",
      "November/2021 - December/2021\n",
      "- Experience with QA/mobile tools(bug-reports, check-lists);\n",
      "- Experience with a Regression tests, Integration, Functional tests, Smoke.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example negative entry \n",
    "exampleNegativeEntry = labeled_df.loc[labeled_df[\"True Label\"] == NEGATIVE_LABEL].iloc[10]\n",
    "print(exampleNegativeEntry.to_dict()[\"CV\"])\n",
    "# print(\"\".join(exampleNegativeEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08830b8e",
   "metadata": {},
   "source": [
    "## Section 2: Prompting LLMs for generating cover letters \n",
    "\n",
    "Now we will use a generic prompt to generate a cover letters for each resume using API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9968e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "with open('llm_api_keys.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "together_api_key = config['services']['together']['api_key'] # replace with openai or anthropic also in yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f48e3c4-fb69-4314-9ab4-d3e0b68a4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example usage of Together AI \n",
    "client = Together(api_key=together_api_key) \n",
    "position = \"Project Manager\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "     model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "     messages=[{\"role\": \"user\", \"content\": \"Modify this resume to help me get a \"+ position+\" Job:\" + \"\".join(\"\".join(exampleNegativeEntry.to_dict()['CV'].split('\\r\\n')).split('\\n'))}],\n",
    " )\n",
    "coverletter = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e40e28-5177-4645-9ccc-a0bab721bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coverletter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8aa7011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69644\n",
      "69645\n"
     ]
    }
   ],
   "source": [
    "# Script to generate resumes\n",
    "\n",
    "df = pd.read_parquet('data/resumes.parquet', engine='pyarrow')\n",
    "\n",
    "java_dev_occupation_df = df[df[\"Position\"]==\"Java Developer\"]\n",
    "\n",
    "java_to_pm_mod_resume = create_modified_resumes(java_dev_occupation_df, 2, \"java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb97ee",
   "metadata": {},
   "source": [
    "## Section 3: Training a simple hiring model \n",
    "\n",
    "We will now use fast text to create a hiring model which will make a binary decision of whether we should hire a candidate or not based on years of experience as the ground truth. Fasttext (https://fasttext.cc/) is an easy to use library you can run on your local computer to build text classification models or get embedding representations for different inputs. Here we will use Fast text to generate embeddings and then use a logistic classifier on top of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b060e-4529-498f-97ee-b4a3016d65e0",
   "metadata": {},
   "source": [
    "### Step 1: Generate embeddings from cover letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b689cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fast text vectors\n",
    "import fasttext\n",
    "#FASTTEXT_MODEL_FILEPATH = \"./cc.en.300.bin\"      \n",
    "FASTTEXT_MODEL_FILEPATH = '../../../Downloads/cc.en.300.bin'\n",
    "ft = fasttext.load_model(FASTTEXT_MODEL_FILEPATH) # replace with your own path to the vector binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b345dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have certificates of successful completion of QATestLab and DataArt testing courses. I was the best support engineer for a few months in my company. Apart from that I also took part in managing support team.',\n",
       " \"Testing new features and new platforms(for online chat), testing companyâs website, finding errors in the system and sending them to system administrators for correction. All my experience before that I got at the courses of testing during my homeworks. In my homeworks I was doing Test Plan, Test Cases, Check Lists, Bug Reports, User stories and wrote metricks about completed work. My homeworks was checked and appreciated. I'm going to start my career in IT with manual testing and in the future, become to automation.\",\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\".join(labeled_df.iloc[12229].to_dict()['CV']).split('\\r\\n').split('\\n')\n",
    "\"\".join(labeled_df.iloc[12229].to_dict()['CV'].split('\\r\\n')).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb52179",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_doordash_pm = \"Tailor my resume to this job description and not make anything up: Product Manager (Multiple Levels) - Doordash: About the Team At DoorDash, we're redefining the future of on-demand delivery. To do this, we're building a world-class product organization, in which each of our product managers play a critical role in helping to define and execute our vision to connect local delivery networks in cities all across the world! About The Role Product Managers at DoorDash require a sharp consumer-first eye, platform thinking and strong cross-functional collaboration. As a Product Manager at DoorDash, you will own the product strategy and vision, define the product roadmap and alignment, and help drive the execution. You will be working on mission-critical products that shape the direction of the company. You will report into one of the following pillars: Merchant, Consumer, Operational Excellence, Ads, Logistics, or New Verticals. This role is a hybrid of remote work and in-person collaboration. Youâre Excited About This Opportunity Because You Willâ¦ Drive the product definition, strategy, and long term vision. You own the roadmap Work closely with cross-functional teams of designers, operators, data scientists and engineers Communicate product plans, benefits and results to key stakeholders including leadership team Weâre Excited About You Becauseâ¦ You have 5+ years of Product Management Industry Experience You have 4+ years of user-facing experience in industries such as eCommerce, technology or multi-sided marketplaces You have proven abilities in driving product strategy, vision, and roadmap alignment Youâre an execution power-house You have experience presenting business reviews to senior executives You have empathy for the users you build for You are passionate about DoorDash and the problems we are solving for About DoorDash At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of usersâfrom Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employeesâ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more. Our Commitment to Diversity and Inclusion Weâre committed to growing and empowering a more inclusive community within our company, industry, and cities. Thatâs why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel. Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on 'protected categories,' we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce â people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination. Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation. If you need any accommodations, please inform your recruiting contact upon initial connection.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8807ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumm = \"\".join(labeled_df.loc[129969].to_dict()['CV'].split('\\r\\n')).split('\\n')\n",
    "resume_qa = \"01.07.2019 - current, QA engineer, Zoolatech On the daily basis, I'm working on implementation, refactoring and improvements of automation test scenarios using Selenium with Java. Purpose improvements into automation test framework. Work with cross-functional teams to identify and develop test cases for functional testing. Provide reports to management on the automation sprint backlog, timing, schedule and results. During my time at Zoolatech got acquainted with such tools as 'Selenium', 'Gitlab', 'Maven', 'TestNG', 'REST Assured', 'JSON.Simple', 'BrowserStack'. Got experience with Page Object Model approach, used Dev Tool to identify Web Elements XPath 01.06.2018 - 01.07.2019, QA engineer, Global Logic On the daily basis, I have been working on creating test cases for new features, updating existing test cases accordingly to the new features, running execution records, open and verifying defects. Gained experience working in an international Scrum team with all appropriate activities. During my time at GlobalLogic got acquainted with such tools as 'Putty', 'WinSCP', 'Cygwin', 'Postman', 'pgAdmin'. Improved business communication skills inside the team (participation in meetings and emailing with Toronto based teammates). Got experience in mentoring and knowledge sharing of product functionality with our new team members. 01.07.2017 - 01.06.2018, QA engineer, Lemonade Agency While working at the Lemonade Agency I gained experience in testing desktop games and mobile applications for IOS and Android, creating bug reports, test cases, and checklists. Got experience working with technical documentation on commercial projects. On the daily basis, I have been working with such programs as Fiddler, Reflector, Adobe Scout, etc.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def8b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.59\n"
     ]
    }
   ],
   "source": [
    "result = get_score(job_doordash_pm, resumm)\n",
    "similarity_score = round(result[0].score * 100, 2)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89517210-8189-4e61-9af8-643ac321be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vector representation of a multiword string using fasttex embeddings\n",
    "def get_vector_rep(text: str): \n",
    "    tokens = text.lower().split() # feel free to use other tokenizations if you want\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        print(tokens)\n",
    "        print(text)\n",
    "        print(len(text))\n",
    "    \n",
    "    for (i, t) in enumerate(tokens):\n",
    "        if i == 0:\n",
    "            vec = ft.get_word_vector(t)\n",
    "        else:\n",
    "            vec += ft.get_word_vector(t)\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.pairwise.cosine_similarity(get_vector_rep(\"in the mood to\").reshape(-1, 1), get_vector_rep(\"hi there\").reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccf783-38f6-423b-a675-3a1fede3d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {0:list(java_dev_occupation_df['CV']), 1: list(pm_occupation_df['CV'])}\n",
    "\n",
    "vector_rep = get_vector_rep(\"\".join(\"\".join(java_dev_occupation_df.iloc[0].to_dict()['CV'].split('\\r\\n')).split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab74eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_train_dataset(true_dataset, false_dataset):\n",
    "    x_s = []\n",
    "    y_s = []\n",
    "    for cv_s in true_dataset:\n",
    "        x_s.append(get_vector_rep(\"\".join(\"\".join(cv_s.split('\\r\\n')).split('\\n'))))\n",
    "        y_s.append(1)\n",
    "    for cv_s in false_dataset:\n",
    "        x_s.append(get_vector_rep(\"\".join(\"\".join(cv_s.split('\\r\\n')).split('\\n'))))\n",
    "        y_s.append(0)\n",
    "    return [x_s, y_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(\"\".join(datasets[0][0].split('\\r\\n')).split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3e37d-fa1f-4304-9f5f-54867b970a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build vector embeddings and lables for positive label examples experience more than 5 years, negative examples less than 5\n",
    "training_data = create_test_train_dataset(datasets[1], datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3b1af-bf5c-470e-8f64-c00d131b44b4",
   "metadata": {},
   "source": [
    "### Step 2: Build classifier for resume classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061ee07-d3b3-4d0a-b050-f91a6a1ad859",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_applicant_modification_data = [training_data[0], training_data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates (model, x_test, y_test) based on input (x, y) data\n",
    "def train_model(data):\n",
    "    x = data[0]\n",
    "    y=data[1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "    clf = LogisticRegression(random_state=16)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    p = clf.predict_proba(x_test)[:, 1]\n",
    "    p_acc = accuracy_score(y_test, p > 0.5)\n",
    "    print(\"clf_acc\", p_acc)\n",
    "    return [clf, x_test, y_test]\n",
    "\n",
    "#Plots confusion matrix\n",
    "def plot_conf_matrix(xtest, ytest, output_model):\n",
    "    cnf_matrix = metrics.confusion_matrix(ytest, output_model.predict(xtest))\n",
    "    class_names=[0,1] # name  of classes\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix', y=1.1)\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89453ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resumes = []\n",
    "\n",
    "with open(\"javadeveloper_to_pm.text\", 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line) >1:\n",
    "            test_resumes.append(get_vector_rep(line))\n",
    "        #print(\"new\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebba9c-71f0-494d-9801-a60086502244",
   "metadata": {},
   "source": [
    "## Section 4: Simulation manipulations and evaluate disparity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57790c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resumes = []\n",
    "\n",
    "with open(\"javadeveloper_to_pm.text\", 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line) >1:\n",
    "            test_resumes.append(get_vector_rep(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Let's train a model on just the non-modified resumes. Does modify the Java SWE resumes increase the chance of acceptance?\n",
    "\n",
    "#train model on unmodified data\n",
    "model_output = train_model(no_applicant_modification_data)\n",
    "print('Intercept: {0}'.format(model_output[0].intercept_))\n",
    "plot_conf_matrix(model_output[1], model_output[2], model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on modified JAVA SWE data. Do these \"0\" datapoints became incorrectly labeled as 1?\n",
    "java_predictions = model_output[0].predict(test_resumes)\n",
    "ratiooffalsepositives = len([i for i in java_predictions if i==1])/len(java_predictions)\n",
    "print(\"THe ratio of FP in the Java SWE modified data, amongst all the JAVA SWE is\", ratiooffalsepositives, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24490c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model on unmodified data\n",
    "model_output = train_model(no_applicant_modification_data)\n",
    "print('Intercept: {0}'.format(model_output[0].intercept_))\n",
    "plot_conf_matrix(model_output[1], model_output[2], model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85373d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0] = test_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"javadeveloper_to_pm.text\", 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283b1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ef90e252922ec218579f878e8875693d0f6f915d658626d8644d9a71eb203b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
